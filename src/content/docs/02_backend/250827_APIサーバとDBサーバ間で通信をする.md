---
title: APIサーバとDBサーバ間で通信をする
publishedDate: 2025-08-27
---

## この記事で取り組むこと

以前 FastAPI を理解するためにバックエンドサーバーを構築する記事を書いた。

https://zenn.dev/micchi55555/articles/ef956188baae8d

**今回はその記事で書いたサンプルコードを書き換えていく**ことで、API サーバと DB サーバでどのようにデータのやり取りが行われているのか理解していきたいと思う。

具体的には以下 A、B を記事の中で取り組む。

**A. スクリプトに埋め込んだデータを DB に移行する**

- DB サーバ上にテーブルを作成する
- 作成したテーブルにデータを入れる

**B. API サーバから DB にアクセスするコードを作成する**

ちなみに、スクリプトに埋め込んだデータというのは、`app/routers/todos.py`だと

```python
samples = [
    {
        "content": "ご飯を炊く",
        "due": date.fromisoformat("2025-10-12"),
        "category": "家事",
        "priority": 4,
    },
    {
        "content": "PostgreSQLの移行手順を整理",
        "due": date.fromisoformat("2025-10-15"),
        "category": "仕事",
        "priority": 5,
    },
    {
        "content": "Vue.jsのUdemy視聴（25%完了）",
        "due": date.fromisoformat("2025-10-20"),
        "category": "勉強",
        "priority": 3,
    },
]
```

`app/routers/categories.py`だと

```python
seeds = ["家事", "仕事", "勉強"]
```

の部分のことを指す（いずれも前の記事から該当部分を抜粋）

## 前提

「**A. スクリプトに埋め込んだデータを DB に移行する**」には、大きく 2 つのやり方がある。

1. SQL を使い、コマンドライン上に直接打ち込むことで行う
2. ORM を使い、Python スクリプトを作成・実行することで行う

今回は API サーバと DB サーバの間でどのようにデータのやり取りを行うか理解することが目的で長期的な運用は見据えていないため、「**1. SQL を使い、コマンドライン上に直接打ち込むことで行う**」のやり方のみ実施する。

## 実際の手順 A. スクリプトに埋め込んだデータを DB に移行する

### 1. 以下のようなフォルダ構成とする

```txt
/home/ユーザー名/projects/
└── backend-study_postgresql-test/
    └── backend
            ├── app # APIサーバのソースコード
            │   └── main.py
            └── db # DB関連のソースコード ※デプロイ時には使われない
                ├── data
                │   ├── todos.csv
                │   └── categories.csv
                └── scripts
                    ├── todos.sql
                    └── categories.sql
```

### 2. DB にログインする

#### 2-1. DB コンテナに入る

```bash
cd /home/ユーザー名/projects/backend-study_postgresql-test/
docker compose -f compose.db.yml -f compose.app.yml up -d --build # コンテナを起動する（していなければここからする）
docker compose -f compose.db.yml exec db bash
```

- db コンテナに入り、bash を起動する
- このコマンドを実行すると、`root@e8657705a57c:/# `と表示される

  - `root`: コンテナでログインしているユーザ名。多くの公式イメージはデフォルトで root ユーザで動く
  - `@e8657705a57c`: 現在入っているコンテナの ID（先頭 12 文字程度）。**毎回コンテナを作るたびに異なる値になる**
  - `:/`: 現在のカレントディレクトリ。最初はコンテナ内のルートディレクトリ`/`にいる
  - `#`: root ユーザーであることを示す記号（一般ユーザーなら`$`が表示される）

  → 「コンテナ内の root ユーザーとして、コンテナ ID`e8657705a57c`上の`/`ディレクトリにいる」状態を表すプロンプトの意

- コマンドの意味（詳細）:

  - `docker compose`: Docker Compose を使ってコンテナを操作するコマンド
  - `-f compose.db.yml`: どの Compose ファイルを使うかを指定
  - `exec`: **実行中のコンテナの中でコマンドを実行する**サブコマンド。`docker run`は新しいコンテナを起動するのに対し、`exec` は既存コンテナの中に入り込むイメージ
  - `db`: コンテナ名ではなく、サービス名（Compose ファイルの`services:`の下に書いてある名前）
  - `bash`: コンテナの中で起動するコマンド。つまり「db サービスのコンテナの中に bash シェルを起動して入る」という意

#### 2-2. コンテナ内で psql を起動して、appdb（データベース名）にログインする

```bash
psql -U appuser -d appdb
```

- 補足 psql とは？ → PostgreSQL の CLI。SQL を直接入力して実行できる対話型のツール。MySQL だと、`mysql`コマンドが対応
- データベースにログインできると以下のようなプロンプトになる

  ```bash
  appdb=>
  ```

- コマンドの意味（詳細）:

  - `-U (ユーザ名)`: 何というユーザで接続するかを指定
  - `-d（データベース名）`: 何というデータベースに接続するかを指定

#### 補足 psql の基本操作

`psql`内では、SQL 文だけでなく「メタコマンド」と呼ばれる特殊なコマンドを使える
すべてバックスラッシュ`\`で始まるのが特徴

- `\l`: データベース一覧を表示する
- `\c (データベース名)`: 指定したデータベースに接続する（connect の略）
- `\dt`: 現在のデータベースにあるテーブル一覧を表示する
- `\d (テーブル名)`: テーブルの定義（カラムや型、制約など）を表示する
- `\q`: psql を終了する（quit の略）

ほか操作（SQL）:

- `DROP TABLE テーブル名;`: テーブルを削除する

### 3. テーブルを作成する

- `backend/db/scripts/categories.sql`に以下を記載。コピーして、コマンドライン上にペーストし、エンターを押すと SQL が実行されて`categories`テーブルができる

```sql
CREATE TABLE categories (
  "id" SMALLINT GENERATED ALWAYS AS IDENTITY PRIMARY KEY,
  "category" TEXT NOT NULL
);
```

- `backend/db/scripts/todos.sql`に以下を記載。コピーして、コマンドライン上にペーストし、エンターを押すと SQL が実行されて`todos`テーブルができる

```sql
CREATE TABLE todos (
  "id" SMALLINT GENERATED ALWAYS AS IDENTITY PRIMARY KEY,
  "content" TEXT NOT NULL,
  "due" DATE,
  "category" SMALLINT NOT NULL,
  "priority" SMALLINT
  ,FOREIGN KEY ("category") REFERENCES "categories"("id") ON UPDATE CASCADE ON DELETE RESTRICT
);
```

- 作成できたことの確認は以下コマンドで実施する

```sql
\dt           -- テーブル一覧表示
\d todos      -- todos テーブルの定義表示
```

### 4. 作成したテーブルにデータを入れる

- まず CSV をホスト → コンテナへコピー（以下コマンドはホストのターミナル上で実行）

```bash
docker compose -f compose.db.yml cp /home/sakih/projects/backend-study_postgesql-test/backend/db/data/todos.csv db:/tmp/todos.csv
docker compose -f compose.db.yml cp /home/sakih/projects/backend-study_postgesql-test/backend/db/data/categories.csv db:/tmp/categories.csv
```

- コンテナの CSV をテーブルに入れる（以下コマンドはコンテナで psql にログイン後、ターミナル上で実行）

```sql
\copy todos FROM '/tmp/todos.csv' WITH (FORMAT csv, HEADER true, ENCODING 'SJIS');
\copy categories FROM '/tmp/categories.csv' WITH (FORMAT csv, HEADER true, ENCODING 'SJIS');
```

- テーブルにデータが入ったことを確認

```sql
SELECT * FROM todos LIMIT 5;
SELECT * FROM categories LIMIT 5;
```

### 補足 テーブル定義のポイント

- **`TEXT`にするか？ or `VARCHAR(n)`にするか？**

  → 違いは文字数制限の有無だけ

- **`INTEGER`にするか？ or `SMALLINT`にするか？**

  → 違いは取り得る値の範囲だけ

## 実際の手順 B. API サーバから DB にアクセスするコードを作成する

- 元のコード

```python
from typing import Annotated, List, Optional
from fastapi import APIRouter, HTTPException, Path, Query
from pydantic import BaseModel, Field

# prefix="/users"：このルーター配下の全パスの先頭に /users が付与される（例：@router.get("/") は実URL /users/）
# tags=["users"]：OpenAPI/Swagger UI 上のグルーピングに使われる
router = APIRouter(prefix="/users", tags=["users"])

# === Pydantic v2 スタイルのモデル ===

# 共通フィールドnameを定義。Fieldで文字長を制約し、OpenAPIにも反映される
class UserBase(BaseModel):
    name: str = Field(min_length=1, max_length=50)

# 作成時の入力用。将来的にemailなどを追加してもUserへの影響を分離できる
class UserCreate(UserBase):
    pass

# 部分更新（PATCH）用。OptionalにしてNoneは「更新しない」を意味する
class UserUpdate(BaseModel):
    name: Optional[str] = Field(default=None, min_length=1, max_length=50)

# レスポンスなどで返す確定形。idを含める
class User(UserBase):
    id: int

# お手軽なインメモリ DB（実務では RDB 等に置き換え）
_FAKE_DB: list[User] = [
    User(id=1, name="Alice"),
    User(id=2, name="Bob"),
]

# データベースにある大量のユーザを、検索でき(q)・必要な件数だけ(limit)・必要な位置から(offset)取り出せるようにできるAPI
# response_model=List[User]：出力のスキーマを固定し、不要なフィールドを除去してOpenAPIにも反映する
@router.get("/", response_model=List[User])
def list_users(
    # 以下、クエリ引数
    q: Annotated[Optional[str], Query(description="部分一致で絞り込み")] = None, # 検索キーワードで部分一致検索
    limit: Annotated[int, Query(ge=1, le=100)] = 50, # 表示レコード数を1-100に制約
    offset: Annotated[int, Query(ge=0)] = 0, # 0以上に制約
):
    """ユーザ一覧を取得する"""
    data = _FAKE_DB
    # 検索キーワードは、空欄でなければ絞り込みされる。なければあるデータ全て表示される
    if q:
        # 検索キーワードに全て小文字にする、かつ、FAKE_DBのname列も全て小文字にして部分一致検索をする
        data = [u for u in data if q.lower() in u.name.lower()]
    return data[offset : offset + limit] # 表示範囲ぶんだけ返す

# ユーザIDがXXのユーザ名を取り出す
# 1つのユーザIDに複数人いれば、複数人が表示される
@router.get("/{user_id}", response_model=User)
def get_user(
    user_id: Annotated[int, Path(ge=1, description="ユーザーID")]
    # Path(ge=1)：パスパラメータuser_idは1以上であることを保証する
):
    user = next((u for u in _FAKE_DB if u.id == user_id), None)
    if not user:
        # HTTPExceptionはFastAPIがJSON化して返す
        raise HTTPException(status_code=404, detail="User not found")
    return user

# 新しいユーザを_FAKE_DBに追加する
# 入力は UserCreate。フィールド検証は自動
# status_code=201：作成成功の慣習に従う。余裕があればLocationヘッダを返す設計も望ましい
@router.post("/", response_model=User, status_code=201)
def create_user(payload: UserCreate):
    # new_id：現在の最大ID+1という単純払い出し。実務ではDBのAutoIncrementやUUIDを使うべき
    new_id = max((u.id for u in _FAKE_DB), default=0) + 1
    user = User(id=new_id, **payload.model_dump())
    _FAKE_DB.append(user)
    return user

# ユーザの情報を更新する
@router.patch("/{user_id}", response_model=User)
def update_user(user_id: int, payload: UserUpdate):
    for i, u in enumerate(_FAKE_DB):
        if u.id == user_id:
            data = u.model_dump()
            patch = {k: v for k, v in payload.model_dump().items() if v is not None}
            data.update(patch)
            _FAKE_DB[i] = User(**data)
            return _FAKE_DB[i]
    raise HTTPException(status_code=404, detail="User not found")

# ユーザの削除をする
# 成功時は本文なしの 204 を返す。RESTの慣習に従う
# 変化がなければ（＝該当IDが無ければ）404を返す
@router.delete("/{user_id}", status_code=204)
def delete_user(user_id: int):
    global _FAKE_DB # 再束縛しているものの、スレッドセーフではない
    before = len(_FAKE_DB)
    _FAKE_DB = [u for u in _FAKE_DB if u.id != user_id]
    if len(_FAKE_DB) == before:
        raise HTTPException(status_code=404, detail="User not found")
    return
```

### 変更箇所その 1: ライブラリの追加

- 以下ライブラリを追加

```python
import os

import psycopg
from psycopg.rows import dict_row
from psycopg.errors import UniqueViolation
```

### 変更箇所その 2: DB に接続

- 以下 DB 関連の環境変数と、DB に接続する関数を定義しておく

```python
PG_USER = os.getenv("POSTGRES_USER", "postgres")
PG_PASSWORD = os.getenv("POSTGRES_PASSWORD", "postgres")
PG_DB = os.getenv("POSTGRES_DB", "appdb")
PG_HOST = os.getenv("POSTGRES_HOST", "db")   # Compose のサービス名が "db" ならこれでOK
PG_PORT = int(os.getenv("POSTGRES_PORT", "5432"))

def _connect():
    # 毎回必要なときに接続し、withブロック終了でクローズ
    return psycopg.connect(
        dbname=PG_DB,
        user=PG_USER,
        password=PG_PASSWORD,
        host=PG_HOST,
        port=PG_PORT,
        autocommit=True,
        row_factory=dict_row,  # dict で受け取れる（カラム名でアクセス）
    )
```

- `autocommit=True`にしておくことで、SQL クエリは即コミットされる
- `autocommit=False`なら、`with`を抜けるまでがトランザクションとなる

### 変更箇所その 3: SQL クエリをたたいてデータを取得

- ユーザの一覧情報をキーワード検索して取得する部分の API の実装を修正する
- 元のコード

```python
@router.get("/", response_model=List[User])
def list_users(
    q: Annotated[Optional[str], Query(description="部分一致で絞り込み")] = None, # 検索キーワードで部分一致検索
    limit: Annotated[int, Query(ge=1, le=100)] = 50, # 表示レコード数を1-100に制約
    offset: Annotated[int, Query(ge=0)] = 0, # 0以上に制約
):
    data = _FAKE_DB
    # 検索キーワードは、空欄でなければ絞り込みされる。なければあるデータ全て表示される
    if q:
        # 検索キーワードに全て小文字にする、かつ、FAKE_DBのname列も全て小文字にして部分一致検索をする
        data = [u for u in data if q.lower() in u.name.lower()]
    return data[offset : offset + limit] # 表示範囲ぶんだけ返す
```

- 変更後のコード

```python
@router.get("/", response_model=List[User])
def list_users(
    q: Annotated[Optional[str], Query(description="部分一致で絞り込み")] = None,
    limit: Annotated[int, Query(ge=1, le=100)] = 50,
    offset: Annotated[int, Query(ge=0)] = 0,
):
    """クエリを作る部分"""
    sql = "SELECT id, name, email FROM users"
    params: list = []

    if q: # qが空でないならWHERE句を追加
        sql += " WHERE name ILIKE %s OR email ILIKE %s" # ILIKE は 大文字小文字を無視した部分一致
        like = f"%{q}%" # 前方一致と後方一致を両方許容
        params.extend([like, like]) # nameあるいはemailにqを含むものをヒットさせる

    sql += " ORDER BY id ASC" # id順に並べる

    sql += " LIMIT %s OFFSET %s" # 表示範囲を絞る
    params.extend([limit, offset])

    """DBにアクセスしてデータを取得する部分"""
    with _connect() as conn, conn.cursor() as cur:
        cur.execute(sql, params)
        rows = cur.fetchall()
    return rows
```

- **作成される SQL のクエリの例**: `q = 'al', limit = 50, offset = 0`の場合

  ← 以下のクエリに 4 つのパラメータ`[%al%, %al%, 50, 0]`が入るイメージ

```sql
SELECT id, name, email FROM users \
 WHERE name ILIKE %s OR email ILIKE %s \
 ORDER BY id ASC \
 LIMIT %s OFFSET %s;
```

- **DB にアクセスしてデータを取得する部分**の解説:

  - `conn`は接続、レストランに入って席についた状態
  - `cursor`はカーソル、注文を受け付けるウェイター
  - `sql`、`params`は注文票
  - `.execute()`で DB に SQL を送る（アクセスする）
  - `.fetchall()`で実行済み SQL の結果を Python に持ってくる
  - `with`文を使うことで、処理が終わった後に自動的にリソース（接続）が閉じられる

    ← DB のコネクション数がムダに消費されないので、サーバが新しい接続を受け付けなくことを防ぐことができる

### 変更箇所その 4: DB にデータを追加

- ユーザの一覧情報に新しいユーザを追加する部分の API の実装を修正する
- 元のコード

```python
@router.post("/", response_model=User, status_code=201)
def create_user(payload: UserCreate):
    # new_id：現在の最大ID+1という単純払い出し。実務ではDBのAutoIncrementやUUIDを使うべき
    new_id = max((u.id for u in _FAKE_DB), default=0) + 1
    user = User(id=new_id, **payload.model_dump())
    _FAKE_DB.append(user)
    return user
```

- 変更後のコード

```python
@router.post("/", response_model=User, status_code=201)
def create_user(payload: UserCreate):
    try:
        with _connect() as conn, conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO users (name, email)
                VALUES (%s, %s)
                RETURNING id, name, email
                """,
                [payload.name, payload.email],
            )
            row = cur.fetchone()
        return row
    except UniqueViolation:
        # email UNIQUE 違反など
        raise HTTPException(status_code=409, detail="Email already exists")
```

- 作成されるクエリの例:

```sql

```

### 変更箇所その 5: DB にあるデータを更新

- 元のコード:

```python

```

- 変更後のコード:

```python

```

### 変更箇所その 6: DB にあるデータを削除

- 元のコード:

```python

```

- 変更後のコード:

```python

```
